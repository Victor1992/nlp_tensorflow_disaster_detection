{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "introduction_to_nlp_in_tensorflow.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNQcQI3dW6cPVQ+wilymxYU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Victor1992/nlp_tensorflow_disaster_detection/blob/main/introduction_to_nlp_in_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to NLP in tensorflow\n",
        "\n",
        "NLP has the goal of deriving information out of natural language( could be sequences text or speech)\n",
        "\n",
        "Another common term for NLP is sequence to sequence problem (seq2seq)."
      ],
      "metadata": {
        "id": "mqeP_ASbmgku"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check for GPU"
      ],
      "metadata": {
        "id": "h6bP8IGgnR-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -L"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAQVxBDYnfJF",
        "outputId": "d2aaf9ef-0df1-4ed2-86cf-55b9fd3c05b8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla K80 (UUID: GPU-49046f02-cb82-102c-a7cd-e3a74d8ed806)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get helper functions\n"
      ],
      "metadata": {
        "id": "OkehjgZknjEm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
        "\n",
        "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBldgC-vpxQR",
        "outputId": "bb6b5f1d-45bf-4dbe-c4d8-2aad8316d632"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-18 08:47:47--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "helper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-12-18 08:47:47 (37.4 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get text dataset\n",
        "\n",
        "The dataset we are going to use is kaggle's dataset fro introduction to NLP dataset (text samples of Tweets labelled as disaster ot not disaster) : https://www.kaggle.com/c/nlp-getting-started\n"
      ],
      "metadata": {
        "id": "akD-fnxnp0Pe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
        "\n",
        "unzip_data('nlp_getting_started.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xp6hOI4vqcMt",
        "outputId": "a9eed325-fd74-498f-afbc-5e2995955b5e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-18 08:47:53--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.189.128, 108.177.97.128, 108.177.125.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.189.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‘nlp_getting_started.zip’\n",
            "\n",
            "\rnlp_getting_started   0%[                    ]       0  --.-KB/s               \rnlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2021-12-18 08:47:53 (38.0 MB/s) - ‘nlp_getting_started.zip’ saved [607343/607343]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize a text dataset"
      ],
      "metadata": {
        "id": "vZ_fRYjzvmEH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")"
      ],
      "metadata": {
        "id": "A5XiiBvZiFSH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "QiFEaBxCiZnh",
        "outputId": "82a14a5f-af48-4f7e-d0ee-22a845b0368e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ...                                               text target\n",
              "0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              "3   6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
              "4   7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle  training data\n",
        "train_df_shuffled = train_df.sample(frac=1, random_state = 42)\n",
        "train_df_shuffled.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "dQ9J5Vh_icMM",
        "outputId": "fc9cc0c1-a5eb-43ff-cd49-7c4077ae6d91"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2644</th>\n",
              "      <td>3796</td>\n",
              "      <td>destruction</td>\n",
              "      <td>NaN</td>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2227</th>\n",
              "      <td>3185</td>\n",
              "      <td>deluge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>7769</td>\n",
              "      <td>police</td>\n",
              "      <td>UK</td>\n",
              "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>191</td>\n",
              "      <td>aftershock</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6845</th>\n",
              "      <td>9810</td>\n",
              "      <td>trauma</td>\n",
              "      <td>Montgomery County, MD</td>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ... target\n",
              "2644  3796  ...      1\n",
              "2227  3185  ...      0\n",
              "5448  7769  ...      1\n",
              "132    191  ...      0\n",
              "6845  9810  ...      0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How test data looks like ?\n",
        "train_df_shuffled.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "PUZciwNEjCBg",
        "outputId": "f7881c20-5737-4b89-91b4-e621fc0f7f6f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2644</th>\n",
              "      <td>3796</td>\n",
              "      <td>destruction</td>\n",
              "      <td>NaN</td>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2227</th>\n",
              "      <td>3185</td>\n",
              "      <td>deluge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>7769</td>\n",
              "      <td>police</td>\n",
              "      <td>UK</td>\n",
              "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>191</td>\n",
              "      <td>aftershock</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6845</th>\n",
              "      <td>9810</td>\n",
              "      <td>trauma</td>\n",
              "      <td>Montgomery County, MD</td>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ... target\n",
              "2644  3796  ...      1\n",
              "2227  3185  ...      0\n",
              "5448  7769  ...      1\n",
              "132    191  ...      0\n",
              "6845  9810  ...      0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How many examples of each class?\n",
        "train_df.target.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RzUY7B6jVE1",
        "outputId": "117d4b71-8039-44b8-ccde-e2ad34fb8502"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# how many total samples?\n",
        "len(train_df), len(test_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcOsSWnmjcyc",
        "outputId": "04d2e53a-621d-47d7-aefc-4fa6bf9e0042"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7613, 3263)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting data into training and testing dataset\n"
      ],
      "metadata": {
        "id": "UnKRWwYYksMl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "0X-OnQ7nrK9j"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n",
        "                                                                             train_df_shuffled[\"target\"].to_numpy(),\n",
        "                                                                             test_size=0.1, # use 10% of data for random split\n",
        "                                                                             random_state=42)"
      ],
      "metadata": {
        "id": "FNghU1OArWHM"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_sentences), len(val_sentences), len(train_labels), len(val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkaIPfSEsLg6",
        "outputId": "5b15e097-d5c0-4d59-e4eb-d516edc10c94"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6851, 762, 6851, 762)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences[:10], train_labels[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Ci1u_vXsaia",
        "outputId": "51e07627-a211-497b-8c9b-964b02b716f2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "        'Imagine getting flattened by Kurt Zouma',\n",
              "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
              "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
              "        'destroy the free fandom honestly',\n",
              "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
              "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
              "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
              "       dtype=object), array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Converting text into numbers"
      ],
      "metadata": {
        "id": "JgqsB3snsi4q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "# Use the default text vectorization parameters\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens=10000, # how many words are there in vocab\n",
        "                  standardize=\"lower_and_strip_punctuation\",\n",
        "                  split=\"whitespace\",\n",
        "                  ngrams=None, # Creating group of n words\n",
        "                  output_mode=\"int\", # how to map tokens to numbers\n",
        "                  output_sequence_length=15, # how long do u wnat ypur sequences to be\n",
        "                  pad_to_max_tokens = True\n",
        "                  )"
      ],
      "metadata": {
        "id": "ecD2tO8nut6o"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the vectorizer to the training text\n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "metadata": {
        "id": "oiZkhRynvcAB"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_sentence = \"Hi i am varun sharma\"\n",
        "text_vectorizer([sample_sentence])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5QSPsG9Wm62",
        "outputId": "09270940-51e9-4930-e2db-647a42f5b7d7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[1663,    8,  160,    1,    1,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# choose a random senetcnce form train sentences and tokenize it\n",
        "import random\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original tweet:\\n {random_sentence}\\\n",
        "        \\n\\n Vectorized version:\")\n",
        "text_vectorizer([random_sentence])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmxf4kn0XFhH",
        "outputId": "a8068f55-7bc5-492a-f6e6-fdb9c9b1ac94"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original tweet:\n",
            " @DrMartyFox     In the U.S. government and Libs made evil good and good evil. We will reap the whirlwind. Lord have mercy on us.        \n",
            "\n",
            " Vectorized version:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[   1,    4,    2,   69,  547,    7,    1,  299, 2121,  136,    7,\n",
              "         136, 2121,   46,   38]])>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the unique words from vocabulary\n",
        "words_in_vocab = text_vectorizer.get_vocabulary() # get all unique words\n",
        "top_5_words = words_in_vocab[:5]\n",
        "bottom_5_words = words_in_vocab[-5:]\n",
        "print(f\"Number of words in Vocab: {len(words_in_vocab)}\")\n",
        "print(f\"5 most common words: {top_5_words}\")\n",
        "print(f\"5 least common words: {bottom_5_words}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYvpeaOLX_ag",
        "outputId": "e5a2ae54-3987-40d5-d8cf-4cc939c7c0cc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in Vocab: 10000\n",
            "5 most common words: ['', '[UNK]', 'the', 'a', 'in']\n",
            "5 least common words: ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating an embedding using embedding layer\n",
        "\n",
        "An embedding is a rich numerical representation of words which can be learned during training\n",
        "\n",
        "To make our embedding, we are going to use Tensotflow embedding layer: https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding\n",
        "\n",
        "The parameters we care about most for our embedding layer:\n",
        "* `input_dim` = the size of our vacabulary\n",
        "* `output_dim` =  the size of the output embedding vector, for example, a value of 100 would mean each token gets represented by a vector 100 long\n",
        "* `input_length` = length of the sequences being passed to the embedding layer"
      ],
      "metadata": {
        "id": "r1z5qN3Baeew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding = layers.Embedding(input_dim = 10000,\n",
        "                             output_dim = 128, # output shape\n",
        "                             input_length = 15)\n",
        "embedding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFbL2ZrRfqXK",
        "outputId": "0cad5c62-c044-45a0-cb36-7f54c2934084"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.embeddings.Embedding at 0x7f84b94f54d0>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a random sentence from atrainig set\n",
        "random_sentence = random.choice(train_sentences)\n",
        "\n",
        "print(f\"Original text:\\n {random_sentence}\\\n",
        "        \\n\\n Embedded Version:\")\n",
        "\n",
        "# Embed the random sentence (turn it into a dense vectors if fixed size)\n",
        "embedding(text_vectorizer([random_sentence]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRuCbUPZg89y",
        "outputId": "9e68cad9-ef96-480a-a7ef-b575b44efbcb"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            " BLOG: Rain much needed as drought conditions worsen: Right now Charlotte and much of the surrounding area haveÛ_ http://t.co/OLzaVTJFKH        \n",
            "\n",
            " Embedded Version:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              "array([[[-0.01041617, -0.03792292, -0.01362002, ..., -0.0133626 ,\n",
              "         -0.013388  ,  0.04361517],\n",
              "        [-0.04102676, -0.01201153, -0.02892603, ...,  0.01181883,\n",
              "          0.03025654,  0.03210194],\n",
              "        [-0.04422691, -0.03274629, -0.02044604, ..., -0.04906574,\n",
              "          0.0141464 , -0.0213517 ],\n",
              "        ...,\n",
              "        [-0.04422691, -0.03274629, -0.02044604, ..., -0.04906574,\n",
              "          0.0141464 , -0.0213517 ],\n",
              "        [-0.0414507 , -0.02506554,  0.01537037, ..., -0.04879241,\n",
              "         -0.01123076,  0.04102829],\n",
              "        [-0.00352373,  0.00878451, -0.03583599, ..., -0.01205517,\n",
              "         -0.03740895, -0.00545676]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "from sklearn import model_selection\n",
        "## Modelling a test dataset( runnign a seroes of experiments)\n",
        "\n",
        "Now as we have turned our text sequences inot numbers, it's time to start building a series of modelling experiements.\n",
        "\n",
        "We'll start with a baseline and move on from there.\n",
        "\n",
        "* Model 0 : Naive Bayes\n",
        "* Model 1 : Feed forward neural network(dense model)\n",
        "* Model 2 : LSTM Model (RNN)\n",
        "* Model 3 : GRU Model (RNN)\n",
        "* Model 4 : Bidirectional-LSTM model_selection\n",
        "* Model 5 : 1D CNN\n",
        "* Model 6 : tensorflow Hub Pretrained Feature Extractor(using transfer learning for NLP)\n",
        "\n",
        "Standear Steps in modelling with tensorflow\n",
        "\n",
        "* Create a  model\n",
        "* Build a model\n",
        "* Fit the model\n",
        "* evaluate a model"
      ],
      "metadata": {
        "id": "R4_AO4dqhYNd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 0: Getting a baseline\n",
        "\n",
        "As with all ML modelling experiments, it's importnant to craete a baseline model so ypu'he got a benchmark for future experiments to build upon.\n",
        "\n",
        "To create our baseline, we'll use Sklearn Multinomial Naive Bayes using the TF_IDF formula to convert our words to numbers\n",
        "\n",
        "**Note:** Its common practice to use non-DL algorithms as a baseline because of their speed and then later using DL to see we can improve upon"
      ],
      "metadata": {
        "id": "bN636jeUsWBj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create Baseline Model (Naive Bayes)"
      ],
      "metadata": {
        "id": "s6Vb2hwQO7U0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# create Tokenization and modelling Pipeline\n",
        "model_0 = Pipeline([\n",
        "                    (\"tfidf\", TfidfVectorizer()), # Convert words into numbers\n",
        "                    (\"clf\", MultinomialNB()) # Model the text \n",
        "])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model_0.fit(train_sentences, train_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcWDXT6Jt4FL",
        "outputId": "8ef3384d-e366-4288-865c-eb397028d9f6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluate the model"
      ],
      "metadata": {
        "id": "VnbUu2yjPHZs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the model\n",
        "baseline_score = model_0.score(val_sentences, val_labels)\n",
        "print(f\"Our Baseline model achieves an accuracy of: {baseline_score*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeANrNDOvEhU",
        "outputId": "da155cb0-1be5-4536-cd80-55281e0ddd79"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our Baseline model achieves an accuracy of: 79.27%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Make Predictions"
      ],
      "metadata": {
        "id": "MJT1ML7MPODa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make Predictions\n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kwon4Bocv_pO",
        "outputId": "c17fd937-aed1-4a3e-9ccd-6cf667e54fb2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Let's evaluate on different Metrics\n",
        "\n",
        "* Accuracy\n",
        "* Precision\n",
        "* Recall\n",
        "* F1-Score"
      ],
      "metadata": {
        "id": "8ZollJMIwTEu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def calculate_results(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Calculates model accuarcy, precision, recall and f1 score of a binar calssification model.\n",
        "  \"\"\"\n",
        "  # calculate model accuracy\n",
        "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "  # Calculate model precision, recall, and f1-score using \"weighted avg\"\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "  model_results = {\n",
        "      \"accuracy\" : model_accuracy,\n",
        "      \"precision\": model_precision,\n",
        "      \"model_recall\" : model_recall,\n",
        "      \"f1\": model_f1\n",
        "  }\n",
        "  return model_results"
      ],
      "metadata": {
        "id": "_biUefEwxKaQ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get Baseline results\n",
        "baseline_results = calculate_results(y_true=val_labels, y_pred = baseline_preds)\n",
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Qfr1ux4zrI_",
        "outputId": "8de9014d-57c7-45b0-960b-fe5887b3c182"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1': 0.7862189758049549,\n",
              " 'model_recall': 0.7926509186351706,\n",
              " 'precision': 0.8111390004213173}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 1. A simple dense layer "
      ],
      "metadata": {
        "id": "ck4mRU1Q0CY0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensorboard callback\n",
        "from helper_functions import create_tensorboard_callback\n",
        "\n",
        "# Create a directory to save Tensorboward logs\n",
        "SAVE_DIR = \"model_logs\""
      ],
      "metadata": {
        "id": "Q2wKTtzIG7te"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build model with the functional api\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "x =text_vectorizer(inputs)\n",
        "x =embedding(x)\n",
        "x= layers.GlobalAveragePooling1D()(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_dense\")"
      ],
      "metadata": {
        "id": "NAnPmkPiHRhI"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkiPSUswH08W",
        "outputId": "03546725-da44-4185-a1ef-54cad30f1076"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 15)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 128)              0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Compile the Model"
      ],
      "metadata": {
        "id": "dauCvBCEPdgf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model_1.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics = [\"accuracy\"])"
      ],
      "metadata": {
        "id": "JTS0HDnYIG6X"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Fit the Model"
      ],
      "metadata": {
        "id": "dcj-hSpIPiEH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "model_1_history = model_1.fit(x= train_sentences,\n",
        "                              y=train_labels,\n",
        "                              epochs =5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR, experiment_name=\"model_1_dense\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O83NUtWzIaGC",
        "outputId": "64a86df4-b546-46d7-a521-198ac2f86e8b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_1_dense/20211218-084801\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 4s 8ms/step - loss: 0.6138 - accuracy: 0.6916 - val_loss: 0.5377 - val_accuracy: 0.7651\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 1s 7ms/step - loss: 0.4444 - accuracy: 0.8189 - val_loss: 0.4689 - val_accuracy: 0.7861\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 1s 6ms/step - loss: 0.3489 - accuracy: 0.8594 - val_loss: 0.4561 - val_accuracy: 0.7887\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 1s 6ms/step - loss: 0.2867 - accuracy: 0.8907 - val_loss: 0.4634 - val_accuracy: 0.7979\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 1s 7ms/step - loss: 0.2400 - accuracy: 0.9136 - val_loss: 0.4776 - val_accuracy: 0.7874\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluate the Model"
      ],
      "metadata": {
        "id": "MhSHUJY6PmYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.evaluate(val_sentences, val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTnPnMqdJAwV",
        "outputId": "0687c8f4-12f8-481f-83e9-ca99de11e56b"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 4ms/step - loss: 0.4776 - accuracy: 0.7874\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4776366949081421, 0.787401556968689]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Make Predictions"
      ],
      "metadata": {
        "id": "LDYx895RPs4f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_preds_probs = model_1.predict(val_sentences)\n",
        "model_1_preds_probs[10]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTFUVQMfMW06",
        "outputId": "57249f18-3429-42bd-8879-48a6fa053bb5"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.11226848], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_labels[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCA8Kau7Mzvx",
        "outputId": "f2d3db32-40c5-45c2-b5a7-7384252ee5e8"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, 1, 1, 1, 1, 1, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert model preictions probablities to label format\n",
        "model_1_preds = tf.squeeze(tf.round(model_1_preds_probs))\n",
        "model_1_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zggE6B6cNEoP",
        "outputId": "e5be327d-dcf3-477a-da11-fee2665e4a24"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evalute the model"
      ],
      "metadata": {
        "id": "qKSXAXH5P0_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate model 1 results\n",
        "model_1_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred = model_1_preds)\n",
        "model_1_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKfNECl3NcrN",
        "outputId": "916e8807-1c19-44a2-e583-9a0c01896580"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.74015748031496,\n",
              " 'f1': 0.7842639469124086,\n",
              " 'model_recall': 0.7874015748031497,\n",
              " 'precision': 0.7927656871284042}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.array(list(model_1_results.values()))  > np.array(list(baseline_results.values()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpVdfCfGNyOc",
        "outputId": "ea7b4956-14e5-4d61-c2ad-746c93b90299"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False, False, False])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 2: Recurrent neural network (RNN)\n",
        "\n",
        "The premise of RNN is to use the representation of previous input to aid the representation of later input\n",
        "\n",
        "LSTM: lomg short term memory\n",
        "\n",
        "Structure of RNN will look like\n",
        "\n",
        "```\n",
        "Input(text) --> Tokenize --> Embedding --> LSTM(RNNs/ dense) --> Output(label Probablity)\n",
        "```\n",
        "\n",
        "**Resources**\n",
        "\n",
        "https://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
        "\n",
        "http://karpathy.github.io/2015/05/21/rnn-effectiveness/\n",
        "\n"
      ],
      "metadata": {
        "id": "kLVB_793OOvx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create LSTM Model"
      ],
      "metadata": {
        "id": "TYtvQgOWfqz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import layers\n",
        "\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x =text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x =layers.LSTM(64)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_2 = tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")\n"
      ],
      "metadata": {
        "id": "CoifaJGJjgYY"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PpZW6k2LkNv1",
        "outputId": "ddd0c5c9-de50-4bc6-d602-a406d1029dbb"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2_LSTM\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 15)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 64)                49408     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,329,473\n",
            "Trainable params: 1,329,473\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Compile the Model"
      ],
      "metadata": {
        "id": "q-omEhtJkIHd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.compile(loss =\"binary_crossentropy\",\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n"
      ],
      "metadata": {
        "id": "ALmH06JTkZSN"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Fit the model"
      ],
      "metadata": {
        "id": "q50KJwK5kprp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_2_history = model_2.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs =5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks = [create_tensorboard_callback(SAVE_DIR, \"model_2_LSTM\") ])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8oipvAikvlE",
        "outputId": "70670ff7-94f4-473b-dd3a-7c17c05feaa6"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_2_LSTM/20211218-084812\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 7s 13ms/step - loss: 0.2265 - accuracy: 0.9158 - val_loss: 0.5521 - val_accuracy: 0.7835\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.1596 - accuracy: 0.9416 - val_loss: 0.5941 - val_accuracy: 0.7848\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.1263 - accuracy: 0.9508 - val_loss: 0.6954 - val_accuracy: 0.7795\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.1038 - accuracy: 0.9610 - val_loss: 0.8122 - val_accuracy: 0.7795\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.0842 - accuracy: 0.9695 - val_loss: 0.8201 - val_accuracy: 0.7703\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Make Predcitions"
      ],
      "metadata": {
        "id": "U_P2HuAvlKyX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_2_pred_probs = model_2.predict(val_sentences)\n",
        "model_2_pred_probs[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrBFlms9lTPO",
        "outputId": "9526fb4f-5033-44ab-e03b-274169572331"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.02351562],\n",
              "       [0.87275714],\n",
              "       [0.9997706 ],\n",
              "       [0.07535937],\n",
              "       [0.00119803]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert model 2 pred probs to labels\n",
        "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
        "model_2_preds[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EciZuCila6O",
        "outputId": "e05e6833-e044-4587-dec8-8e8548b64409"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5,), dtype=float32, numpy=array([0., 1., 1., 0., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluate Model 2 "
      ],
      "metadata": {
        "id": "e-F-AqKjl00H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_2_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_2_preds)\n",
        "model_2_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CT2jDkn3l8Mk",
        "outputId": "a6068ab1-06f2-4244-81de-22db4bab834f"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.03412073490814,\n",
              " 'f1': 0.7679241301282296,\n",
              " 'model_recall': 0.7703412073490814,\n",
              " 'precision': 0.7726339681635592}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KPkO3ePmSJN",
        "outputId": "e2f33c52-2191-477e-ff56-d028a17029f1"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1': 0.7862189758049549,\n",
              " 'model_recall': 0.7926509186351706,\n",
              " 'precision': 0.8111390004213173}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(list(model_2_results.values())) > np.array(list(model_2_results.values()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82IghMQtmYJi",
        "outputId": "313ed5a0-23cb-4f57-eebc-0e935518f7c3"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False, False, False])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 3: GRU\n",
        "\n",
        "**Resourse**\n",
        "\n",
        "https://towardsdatascience.com/understanding-gru-networks-2ef37df6c9be"
      ],
      "metadata": {
        "id": "8S5-0qyHmreW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create GRU model"
      ],
      "metadata": {
        "id": "S5S6Aops2K-K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "x =embedding(x)\n",
        "x =layers.GRU(64)(x)\n",
        "# print(x.shape)\n",
        "# x =layers.GRU(64, return_sequences =True)(x)\n",
        "# print(x.shape)\n",
        "# x =layers.LSTM(42, return_sequences= True)(x)\n",
        "# print(x.shape)\n",
        "# x =layers.GRU(99)(x)\n",
        "# print(x.shape)\n",
        "# x = layers.Dense(64, activation=\"relu\")(x)\n",
        "\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_3 = tf.keras.Model(inputs, outputs, name=\"model_3_GRU\")"
      ],
      "metadata": {
        "id": "SqmCTNkc2R-O"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZuWZRii4NOX",
        "outputId": "422fc09b-4338-4147-e715-6b7405779cf1"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3_GRU\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 15)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 64)                37248     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,317,313\n",
            "Trainable params: 1,317,313\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Compile the model\n"
      ],
      "metadata": {
        "id": "Y04Y7vOx4fmw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.compile(loss= \"binary_crossentropy\",\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics = [\"accuracy\"]) "
      ],
      "metadata": {
        "id": "JwYHFett5Dbb"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Fit the model"
      ],
      "metadata": {
        "id": "9UqiDq0z5TPv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_3_history = model_3.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs =5,\n",
        "                              validation_data = (val_sentences, val_labels),\n",
        "                              callbacks =[create_tensorboard_callback(SAVE_DIR, \"model_3_GRU\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWpo74Nl5WgV",
        "outputId": "4c52f523-7631-4b12-c410-38699b7c04e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_3_GRU/20211218-084836\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 5s 12ms/step - loss: 0.1609 - accuracy: 0.9369 - val_loss: 0.9024 - val_accuracy: 0.7782\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.0844 - accuracy: 0.9680 - val_loss: 0.8887 - val_accuracy: 0.7743\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.0704 - accuracy: 0.9730 - val_loss: 0.9756 - val_accuracy: 0.7730\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.0631 - accuracy: 0.9743 - val_loss: 0.9492 - val_accuracy: 0.7730\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.0527 - accuracy: 0.9777 - val_loss: 1.3095 - val_accuracy: 0.7743\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Make Predictions"
      ],
      "metadata": {
        "id": "1Cn2ecFN5wmc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_3_pred_probs = model_3.predict(val_sentences)\n",
        "model_3_pred_probs[:10]"
      ],
      "metadata": {
        "id": "i08RZCds56jM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert model 3 pred probs to labels\n",
        "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))\n",
        "model_3_preds[:10]"
      ],
      "metadata": {
        "id": "Mk4g-kvF6GW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluate model 3\n"
      ],
      "metadata": {
        "id": "9__IJg6u6bS7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_3_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred = model_3_preds)\n",
        "model_3_results"
      ],
      "metadata": {
        "id": "38gaaJ8A6lv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(list(model_3_results.values())) > np.array(list(baseline_results.values()))"
      ],
      "metadata": {
        "id": "L1lvmfCp6zji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 4 Bidirectional RNN"
      ],
      "metadata": {
        "id": "Mo4T8pKL69AX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create a Bidirectional RNN Model "
      ],
      "metadata": {
        "id": "x7p9DhLnH-Qn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_4 = tf.keras.Model(inputs, outputs, name=\"model_4_bidirectional\") "
      ],
      "metadata": {
        "id": "GB4GHTvbIH48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_4.summary()"
      ],
      "metadata": {
        "id": "f-mavnW3I_qi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Compile the model"
      ],
      "metadata": {
        "id": "p4ulPy6NJB4R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_4.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics = [\"accuracy\"])"
      ],
      "metadata": {
        "id": "mYflWeVyJJ-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Fit the model"
      ],
      "metadata": {
        "id": "AX2odu7RJWX2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_4_history = model_4.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"model_4_bidirectional\")])"
      ],
      "metadata": {
        "id": "e-Vmaq_nKCo2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Make Predictions"
      ],
      "metadata": {
        "id": "IItVtBWBKnYh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_4_pred_probs = model_4.predict(val_sentences)"
      ],
      "metadata": {
        "id": "wl94ySNnK21i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert pred probs to pred labels\n",
        "model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))\n",
        "model_4_preds[:10]"
      ],
      "metadata": {
        "id": "FKwurn82K95c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Calculate the results"
      ],
      "metadata": {
        "id": "lot2M-5TLcfD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_4_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred = model_4_preds)\n",
        "model_4_results"
      ],
      "metadata": {
        "id": "9xxE5RUJLiYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 5 Convolutional Neural Network for Text\n",
        "\n",
        "Typical structure of a Conv1D model for sequences(text)\n",
        "\n",
        "```\n",
        "Inputs(text)--> Tokenization--> Embedding-->Layers(typically ConvD+ Pooling) -> ouputs (class probablities)\n",
        "```"
      ],
      "metadata": {
        "id": "saSSrFrBL1Ee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test our embedding , Conv1d and max pooling\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding_test = embedding(text_vectorizer([\"this is a test sentence\"]))\n",
        "conv_1d = layers.Conv1D(filters=32,\n",
        "                        kernel_size=5,\n",
        "                        strides=1,\n",
        "                        activation=\"relu\", # relu = id value is -ve it converst to 0, and if +ve it remains the same\n",
        "                        padding=\"valid\")\n",
        "conv_1d_output = conv_1d(embedding_test)\n",
        "max_pool = layers.GlobalMaxPool1D()\n",
        "max_pool_output = max_pool(conv_1d_output)\n",
        "\n",
        "embedding_test.shape, conv_1d_output.shape, max_pool_output.shape"
      ],
      "metadata": {
        "id": "im49gJXQPlgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Ovb8NHoGYgeI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}